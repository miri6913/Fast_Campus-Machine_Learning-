{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jarvis\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\pkg_resources\\__init__.py:126: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2-msvc is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading (수술 時 사망 데이터)\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/GonieAhn/Data-Science-online-course-from-gonie/main/Data%20Store/example_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>censor</th>\n",
       "      <th>event</th>\n",
       "      <th>age</th>\n",
       "      <th>wtkg</th>\n",
       "      <th>hemo</th>\n",
       "      <th>homo</th>\n",
       "      <th>drugs</th>\n",
       "      <th>karnof</th>\n",
       "      <th>oprior</th>\n",
       "      <th>z30</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>str2</th>\n",
       "      <th>strat</th>\n",
       "      <th>symptom</th>\n",
       "      <th>cd40</th>\n",
       "      <th>cd420</th>\n",
       "      <th>cd496</th>\n",
       "      <th>r</th>\n",
       "      <th>cd80</th>\n",
       "      <th>cd820</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.340226</td>\n",
       "      <td>801.236842</td>\n",
       "      <td>35.225564</td>\n",
       "      <td>76.061855</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.640977</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>95.432331</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.546992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.580827</td>\n",
       "      <td>1.981203</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>353.204887</td>\n",
       "      <td>336.139098</td>\n",
       "      <td>173.146617</td>\n",
       "      <td>0.603383</td>\n",
       "      <td>987.250000</td>\n",
       "      <td>928.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474231</td>\n",
       "      <td>326.887929</td>\n",
       "      <td>8.852094</td>\n",
       "      <td>13.224698</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>0.480165</td>\n",
       "      <td>0.323410</td>\n",
       "      <td>5.981856</td>\n",
       "      <td>0.170955</td>\n",
       "      <td>0.498255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391056</td>\n",
       "      <td>0.493888</td>\n",
       "      <td>0.905946</td>\n",
       "      <td>0.373589</td>\n",
       "      <td>114.105253</td>\n",
       "      <td>130.961573</td>\n",
       "      <td>191.455406</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>475.223907</td>\n",
       "      <td>438.569798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>47.401000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>535.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>243.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>653.250000</td>\n",
       "      <td>626.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>933.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>330.500000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>818.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>83.502000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1231.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>771.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4255.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           censor        event         age        wtkg        hemo  \\\n",
       "count  532.000000   532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.340226   801.236842   35.225564   76.061855    0.078947   \n",
       "std      0.474231   326.887929    8.852094   13.224698    0.269910   \n",
       "min      0.000000    33.000000   13.000000   47.401000    0.000000   \n",
       "25%      0.000000   535.750000   29.000000   67.500000    0.000000   \n",
       "50%      0.000000   933.500000   34.000000   74.600000    0.000000   \n",
       "75%      1.000000  1081.000000   40.000000   83.502000    0.000000   \n",
       "max      1.000000  1231.000000   70.000000  149.000000    1.000000   \n",
       "\n",
       "             homo       drugs      karnof      oprior         z30  ...  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  ...   \n",
       "mean     0.640977    0.118421   95.432331    0.030075    0.546992  ...   \n",
       "std      0.480165    0.323410    5.981856    0.170955    0.498255  ...   \n",
       "min      0.000000    0.000000   70.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000   90.000000    0.000000    0.000000  ...   \n",
       "50%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "75%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "max      1.000000    1.000000  100.000000    1.000000    1.000000  ...   \n",
       "\n",
       "           gender        str2       strat     symptom        cd40       cd420  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.812030    0.580827    1.981203    0.167293  353.204887  336.139098   \n",
       "std      0.391056    0.493888    0.905946    0.373589  114.105253  130.961573   \n",
       "min      0.000000    0.000000    1.000000    0.000000  103.000000   49.000000   \n",
       "25%      1.000000    0.000000    1.000000    0.000000  271.000000  243.750000   \n",
       "50%      1.000000    1.000000    2.000000    0.000000  346.000000  330.500000   \n",
       "75%      1.000000    1.000000    3.000000    0.000000  422.000000  418.000000   \n",
       "max      1.000000    1.000000    3.000000    1.000000  771.000000  909.000000   \n",
       "\n",
       "            cd496           r         cd80        cd820  \n",
       "count  532.000000  532.000000   532.000000   532.000000  \n",
       "mean   173.146617    0.603383   987.250000   928.214286  \n",
       "std    191.455406    0.489656   475.223907   438.569798  \n",
       "min     -1.000000    0.000000   221.000000   150.000000  \n",
       "25%     -1.000000    0.000000   653.250000   626.500000  \n",
       "50%    113.000000    1.000000   881.000000   818.000000  \n",
       "75%    324.000000    1.000000  1190.000000  1164.000000  \n",
       "max    857.000000    1.000000  4255.000000  3130.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Name Cleaning\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['censor', 'event', 'age', 'wtkg', 'hemo', 'homo', 'drugs', 'karnof',\n",
       "       'oprior', 'z30', 'zprior', 'preanti', 'race', 'gender', 'str2', 'strat',\n",
       "       'symptom', 'cd40', 'cd420', 'cd496', 'r', 'cd80', 'cd820'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data Shape : (532, 22)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Checking\n",
    "col = []\n",
    "missing = []\n",
    "level = [] \n",
    "for name in data.columns:\n",
    "    \n",
    "    # Missing\n",
    "    missper = data[name].isnull().sum() / data.shape[0]\n",
    "    missing.append(round(missper, 4))\n",
    "\n",
    "    # Leveling\n",
    "    lel = data[name].dropna()\n",
    "    level.append(len(list(set(lel))))\n",
    "\n",
    "    # Columns\n",
    "    col.append(name)\n",
    "\n",
    "summary = pd.concat([pd.DataFrame(col, columns=['name']), \n",
    "                     pd.DataFrame(missing, columns=['Missing Percentage']), \n",
    "                     pd.DataFrame(level, columns=['Level'])], axis=1)\n",
    "\n",
    "drop_col = summary['name'][(summary['Level'] <= 1) | (summary['Missing Percentage'] >= 0.8)]\n",
    "data.drop(columns=drop_col, inplace=True)\n",
    "print(\">>>> Data Shape : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    zprior\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Missing Percentage</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>censor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wtkg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hemo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>homo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drugs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karnof</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>z30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>preanti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>str2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>strat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>symptom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cd40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cd420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cd496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cd80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cd820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  Missing Percentage  Level\n",
       "0    censor                 0.0      2\n",
       "1     event                 0.0    358\n",
       "2       age                 0.0     52\n",
       "3      wtkg                 0.0    312\n",
       "4      hemo                 0.0      2\n",
       "5      homo                 0.0      2\n",
       "6     drugs                 0.0      2\n",
       "7    karnof                 0.0      4\n",
       "8    oprior                 0.0      2\n",
       "9       z30                 0.0      2\n",
       "10   zprior                 0.0      1\n",
       "11  preanti                 0.0    273\n",
       "12     race                 0.0      2\n",
       "13   gender                 0.0      2\n",
       "14     str2                 0.0      2\n",
       "15    strat                 0.0      3\n",
       "16  symptom                 0.0      2\n",
       "17     cd40                 0.0    278\n",
       "18    cd420                 0.0    314\n",
       "19    cd496                 0.0    231\n",
       "20        r                 0.0      2\n",
       "21     cd80                 0.0    416\n",
       "22    cd820                 0.0    423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "Y = data['censor']\n",
    "X = data.drop(columns=['censor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 372\n",
      ">>>> # of valid data : 160\n",
      ">>>> # of Train data Y : Counter({0: 241, 1: 131})\n",
      ">>>> # of valid data Y : Counter({0: 110, 1: 50})\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))\n",
    "print(\">>>> # of Train data Y : {}\".format(Counter(Y.iloc[train_idx])))\n",
    "print(\">>>> # of valid data Y : {}\".format(Counter(Y.iloc[valid_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 29 102]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8360655737704918\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 1 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 30 101]]\n",
      "Train Acc : 0.8897849462365591\n",
      "Train F1-Score : 0.831275720164609\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 2 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 31 100]]\n",
      "Train Acc : 0.8870967741935484\n",
      "Train F1-Score : 0.8264462809917356\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 3 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[231  10]\n",
      " [ 13 118]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9111969111969112\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8108108108108109\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 4 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9118773946360154\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 5 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 14 117]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9034749034749036\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 6 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[221  20]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.8814814814814815\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 7 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[220  21]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9112903225806451\n",
      "Train F1-Score : 0.8782287822878228\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 8 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[223  18]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9247311827956989\n",
      "Train F1-Score : 0.8962962962962964\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 9 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9623655913978495\n",
      "Train F1-Score : 0.9453124999999999\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8181818181818182\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 10 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [  9 122]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9420849420849421\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 11 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9416342412451363\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 12 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.8769230769230768\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.8596491228070174\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 13 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9274193548387096\n",
      "Train F1-Score : 0.8981132075471697\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 14 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 21 110]]\n",
      "Train Acc : 0.9059139784946236\n",
      "Train F1-Score : 0.8627450980392157\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 15 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9543010752688172\n",
      "Train F1-Score : 0.9333333333333332\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 16 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9302325581395349\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 17 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9296875\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 18 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9354838709677419\n",
      "Train F1-Score : 0.9097744360902255\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 19 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9354838709677419\n",
      "Train F1-Score : 0.9097744360902255\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 20 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [  7 124]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9323308270676691\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 21 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  4 127]]\n",
      "Train Acc : 0.978494623655914\n",
      "Train F1-Score : 0.9694656488549618\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 22 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9704301075268817\n",
      "Train F1-Score : 0.9578544061302683\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8421052631578947\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 23 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9731182795698925\n",
      "Train F1-Score : 0.9615384615384615\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 24 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9049429657794676\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 25 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9049429657794676\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 26 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[225  16]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9029850746268656\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 27 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9731182795698925\n",
      "Train F1-Score : 0.9615384615384615\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8392857142857143\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 28 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  8 123]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9534883720930233\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 29 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [  7 124]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9538461538461538\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 30 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [  4 127]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9548872180451129\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 31 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [  8 123]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9425287356321839\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8421052631578947\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 32 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [  3 128]]\n",
      "Train Acc : 0.9758064516129032\n",
      "Train F1-Score : 0.9660377358490565\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 33 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.831858407079646\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 34 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 35 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.831858407079646\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# n_estimators\n",
    "n_tree = [5, 10, 20]\n",
    "# learning_rate\n",
    "l_rate = [0.1, 0.3]\n",
    "# max_depth\n",
    "m_depth = [3, 5]\n",
    "# reg_alpha\n",
    "L1_norm = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Modeling\n",
    "save_n = []\n",
    "save_l = []\n",
    "save_m = []\n",
    "save_L1 = []\n",
    "f1_score_ = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for n in n_tree:\n",
    "    for l in l_rate:\n",
    "        for m in m_depth:\n",
    "            for L1 in L1_norm:\n",
    "                \n",
    "                print(\">>> {} <<<\".format(cnt))\n",
    "                cnt +=1\n",
    "                print(\"n_estimators : {}, learning_rate : {}, max_depth : {}, reg_alpha : {}\".format(n, l, m, L1))\n",
    "                model = XGBClassifier(n_estimators=n, learning_rate=l, \n",
    "                                      max_depth=m, reg_alpha=L1, objective='binary:logistic', random_state=119)\n",
    "                model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "                \n",
    "                \n",
    "                # Train Acc\n",
    "                y_pre_train = model.predict(X.iloc[train_idx])\n",
    "                cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "                print(\"Train Confusion Matrix\")\n",
    "                print(cm_train)\n",
    "                print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "                print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "                # Test Acc\n",
    "                y_pre_test = model.predict(X.iloc[valid_idx])\n",
    "                cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "                print(\"Test Confusion Matrix\")\n",
    "                print(cm_test)\n",
    "                print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "                print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                save_n.append(n)\n",
    "                save_l.append(l)\n",
    "                save_m.append(m)\n",
    "                save_L1.append(L1)\n",
    "                f1_score_.append(f1_score(Y.iloc[valid_idx], y_pre_test))\n",
    "                \n",
    "                # Model 저장\n",
    "                #import joblib\n",
    "                #joblib.dump(model, './XGBoost_model/Result_{}_{}_{}_{}_{}.pkl'.format(n, l, m, L1, round(f1_score_[-1], 4)))\n",
    "                #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "Best Test f1-score : 0.8648648648648649\n",
      "Best n_estimators : 5\n",
      "Best Learning Rate : 0.1\n",
      "Best Max_depth : 3\n",
      "Best L1-norm : 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\">>> {} <<<\\nBest Test f1-score : {}\\nBest n_estimators : {}\\nBest Learning Rate : {}\\nBest Max_depth : {}\\nBest L1-norm : {}\".format(np.argmax(f1_score_),\n",
    "                                                                                                                                            f1_score_[np.argmax(f1_score_)], \n",
    "                                                                                                                                            save_n[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_l[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_m[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_L1[np.argmax(f1_score_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 29 102]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8360655737704918\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators=save_n[np.argmax(f1_score_)], learning_rate=save_l[np.argmax(f1_score_)], \n",
    "                           max_depth=save_m[np.argmax(f1_score_)], reg_alpha=save_L1[np.argmax(f1_score_)], objective='binary:logistic', \n",
    "                           random_state=119)\n",
    "best_model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "\n",
    "# Train Acc\n",
    "y_pre_train = best_model.predict(X.iloc[train_idx])\n",
    "cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(cm_train)\n",
    "print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "# Test Acc\n",
    "y_pre_test = best_model.predict(X.iloc[valid_idx])\n",
    "cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(cm_test)\n",
    "print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Score  Feature\n",
      "0   0.551445    event\n",
      "1   0.146731    cd496\n",
      "2   0.084446    cd420\n",
      "3   0.084073  preanti\n",
      "4   0.029171      age\n",
      "5   0.028750     cd80\n",
      "6   0.027590      z30\n",
      "7   0.023935     wtkg\n",
      "8   0.012641   karnof\n",
      "9   0.011218     cd40\n",
      "10  0.000000  symptom\n",
      "11  0.000000    strat\n",
      "12  0.000000     str2\n",
      "13  0.000000     race\n",
      "14  0.000000        r\n",
      "15  0.000000   oprior\n",
      "16  0.000000     homo\n",
      "17  0.000000     hemo\n",
      "18  0.000000   gender\n",
      "19  0.000000    drugs\n",
      "20  0.000000    cd820\n"
     ]
    }
   ],
   "source": [
    "feature_map = pd.DataFrame(sorted(zip(best_model.feature_importances_, X.columns), reverse=True), columns=['Score', 'Feature'])\n",
    "print(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importance Score Top 10\n",
    "feature_map_10 = feature_map.iloc[:10]\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Score\", y=\"Feature\", data=feature_map_10.sort_values(by=\"Score\", ascending=False), errwidth=40)\n",
    "plt.title('XGBoost Importance Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
