{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jarvis\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\pkg_resources\\__init__.py:126: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2-msvc is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading (수술 時 사망 데이터)\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/GonieAhn/Data-Science-online-course-from-gonie/main/Data%20Store/example_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>censor</th>\n",
       "      <th>event</th>\n",
       "      <th>age</th>\n",
       "      <th>wtkg</th>\n",
       "      <th>hemo</th>\n",
       "      <th>homo</th>\n",
       "      <th>drugs</th>\n",
       "      <th>karnof</th>\n",
       "      <th>oprior</th>\n",
       "      <th>z30</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>str2</th>\n",
       "      <th>strat</th>\n",
       "      <th>symptom</th>\n",
       "      <th>cd40</th>\n",
       "      <th>cd420</th>\n",
       "      <th>cd496</th>\n",
       "      <th>r</th>\n",
       "      <th>cd80</th>\n",
       "      <th>cd820</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.340226</td>\n",
       "      <td>801.236842</td>\n",
       "      <td>35.225564</td>\n",
       "      <td>76.061855</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.640977</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>95.432331</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.546992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.580827</td>\n",
       "      <td>1.981203</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>353.204887</td>\n",
       "      <td>336.139098</td>\n",
       "      <td>173.146617</td>\n",
       "      <td>0.603383</td>\n",
       "      <td>987.250000</td>\n",
       "      <td>928.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474231</td>\n",
       "      <td>326.887929</td>\n",
       "      <td>8.852094</td>\n",
       "      <td>13.224698</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>0.480165</td>\n",
       "      <td>0.323410</td>\n",
       "      <td>5.981856</td>\n",
       "      <td>0.170955</td>\n",
       "      <td>0.498255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391056</td>\n",
       "      <td>0.493888</td>\n",
       "      <td>0.905946</td>\n",
       "      <td>0.373589</td>\n",
       "      <td>114.105253</td>\n",
       "      <td>130.961573</td>\n",
       "      <td>191.455406</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>475.223907</td>\n",
       "      <td>438.569798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>47.401000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>535.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>243.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>653.250000</td>\n",
       "      <td>626.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>933.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>330.500000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>818.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>83.502000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1231.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>771.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4255.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           censor        event         age        wtkg        hemo  \\\n",
       "count  532.000000   532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.340226   801.236842   35.225564   76.061855    0.078947   \n",
       "std      0.474231   326.887929    8.852094   13.224698    0.269910   \n",
       "min      0.000000    33.000000   13.000000   47.401000    0.000000   \n",
       "25%      0.000000   535.750000   29.000000   67.500000    0.000000   \n",
       "50%      0.000000   933.500000   34.000000   74.600000    0.000000   \n",
       "75%      1.000000  1081.000000   40.000000   83.502000    0.000000   \n",
       "max      1.000000  1231.000000   70.000000  149.000000    1.000000   \n",
       "\n",
       "             homo       drugs      karnof      oprior         z30  ...  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  ...   \n",
       "mean     0.640977    0.118421   95.432331    0.030075    0.546992  ...   \n",
       "std      0.480165    0.323410    5.981856    0.170955    0.498255  ...   \n",
       "min      0.000000    0.000000   70.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000   90.000000    0.000000    0.000000  ...   \n",
       "50%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "75%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "max      1.000000    1.000000  100.000000    1.000000    1.000000  ...   \n",
       "\n",
       "           gender        str2       strat     symptom        cd40       cd420  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.812030    0.580827    1.981203    0.167293  353.204887  336.139098   \n",
       "std      0.391056    0.493888    0.905946    0.373589  114.105253  130.961573   \n",
       "min      0.000000    0.000000    1.000000    0.000000  103.000000   49.000000   \n",
       "25%      1.000000    0.000000    1.000000    0.000000  271.000000  243.750000   \n",
       "50%      1.000000    1.000000    2.000000    0.000000  346.000000  330.500000   \n",
       "75%      1.000000    1.000000    3.000000    0.000000  422.000000  418.000000   \n",
       "max      1.000000    1.000000    3.000000    1.000000  771.000000  909.000000   \n",
       "\n",
       "            cd496           r         cd80        cd820  \n",
       "count  532.000000  532.000000   532.000000   532.000000  \n",
       "mean   173.146617    0.603383   987.250000   928.214286  \n",
       "std    191.455406    0.489656   475.223907   438.569798  \n",
       "min     -1.000000    0.000000   221.000000   150.000000  \n",
       "25%     -1.000000    0.000000   653.250000   626.500000  \n",
       "50%    113.000000    1.000000   881.000000   818.000000  \n",
       "75%    324.000000    1.000000  1190.000000  1164.000000  \n",
       "max    857.000000    1.000000  4255.000000  3130.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Name Cleaning\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['censor', 'event', 'age', 'wtkg', 'hemo', 'homo', 'drugs', 'karnof',\n",
       "       'oprior', 'z30', 'zprior', 'preanti', 'race', 'gender', 'str2', 'strat',\n",
       "       'symptom', 'cd40', 'cd420', 'cd496', 'r', 'cd80', 'cd820'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data Shape : (532, 22)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Checking\n",
    "col = []\n",
    "missing = []\n",
    "level = [] \n",
    "for name in data.columns:\n",
    "    \n",
    "    # Missing\n",
    "    missper = data[name].isnull().sum() / data.shape[0]\n",
    "    missing.append(round(missper, 4))\n",
    "\n",
    "    # Leveling\n",
    "    lel = data[name].dropna()\n",
    "    level.append(len(list(set(lel))))\n",
    "\n",
    "    # Columns\n",
    "    col.append(name)\n",
    "\n",
    "summary = pd.concat([pd.DataFrame(col, columns=['name']), \n",
    "                     pd.DataFrame(missing, columns=['Missing Percentage']), \n",
    "                     pd.DataFrame(level, columns=['Level'])], axis=1)\n",
    "\n",
    "drop_col = summary['name'][(summary['Level'] <= 1) | (summary['Missing Percentage'] >= 0.8)]\n",
    "data.drop(columns=drop_col, inplace=True)\n",
    "print(\">>>> Data Shape : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    zprior\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Missing Percentage</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>censor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wtkg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hemo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>homo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drugs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karnof</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>z30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>preanti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>str2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>strat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>symptom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cd40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cd420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cd496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cd80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cd820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  Missing Percentage  Level\n",
       "0    censor                 0.0      2\n",
       "1     event                 0.0    358\n",
       "2       age                 0.0     52\n",
       "3      wtkg                 0.0    312\n",
       "4      hemo                 0.0      2\n",
       "5      homo                 0.0      2\n",
       "6     drugs                 0.0      2\n",
       "7    karnof                 0.0      4\n",
       "8    oprior                 0.0      2\n",
       "9       z30                 0.0      2\n",
       "10   zprior                 0.0      1\n",
       "11  preanti                 0.0    273\n",
       "12     race                 0.0      2\n",
       "13   gender                 0.0      2\n",
       "14     str2                 0.0      2\n",
       "15    strat                 0.0      3\n",
       "16  symptom                 0.0      2\n",
       "17     cd40                 0.0    278\n",
       "18    cd420                 0.0    314\n",
       "19    cd496                 0.0    231\n",
       "20        r                 0.0      2\n",
       "21     cd80                 0.0    416\n",
       "22    cd820                 0.0    423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "Y = data['censor']\n",
    "X = data.drop(columns=['censor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 372\n",
      ">>>> # of valid data : 160\n",
      ">>>> # of Train data Y : Counter({0: 241, 1: 131})\n",
      ">>>> # of valid data Y : Counter({0: 110, 1: 50})\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))\n",
    "print(\">>>> # of Train data Y : {}\".format(Counter(Y.iloc[train_idx])))\n",
    "print(\">>>> # of valid data Y : {}\".format(Counter(Y.iloc[valid_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 29 102]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8360655737704918\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 1 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 30 101]]\n",
      "Train Acc : 0.8897849462365591\n",
      "Train F1-Score : 0.831275720164609\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 2 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 31 100]]\n",
      "Train Acc : 0.8870967741935484\n",
      "Train F1-Score : 0.8264462809917356\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 3 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[231  10]\n",
      " [ 13 118]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9111969111969112\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8108108108108109\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 4 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9118773946360154\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 5 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 14 117]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9034749034749036\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 6 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[221  20]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.8814814814814815\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 7 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[220  21]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9112903225806451\n",
      "Train F1-Score : 0.8782287822878228\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 8 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[223  18]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9247311827956989\n",
      "Train F1-Score : 0.8962962962962964\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 9 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9623655913978495\n",
      "Train F1-Score : 0.9453124999999999\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8181818181818182\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 10 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [  9 122]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9420849420849421\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 11 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9416342412451363\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 12 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.8769230769230768\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.8596491228070174\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 13 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9274193548387096\n",
      "Train F1-Score : 0.8981132075471697\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 14 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 21 110]]\n",
      "Train Acc : 0.9059139784946236\n",
      "Train F1-Score : 0.8627450980392157\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 15 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9543010752688172\n",
      "Train F1-Score : 0.9333333333333332\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 16 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9302325581395349\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 17 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9296875\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 18 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9354838709677419\n",
      "Train F1-Score : 0.9097744360902255\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 19 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9354838709677419\n",
      "Train F1-Score : 0.9097744360902255\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 20 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [  7 124]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9323308270676691\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 21 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  4 127]]\n",
      "Train Acc : 0.978494623655914\n",
      "Train F1-Score : 0.9694656488549618\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 22 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9704301075268817\n",
      "Train F1-Score : 0.9578544061302683\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8421052631578947\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 23 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9731182795698925\n",
      "Train F1-Score : 0.9615384615384615\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 24 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9049429657794676\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 25 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9049429657794676\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 26 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[225  16]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9029850746268656\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 27 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9731182795698925\n",
      "Train F1-Score : 0.9615384615384615\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8392857142857143\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 28 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  8 123]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9534883720930233\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 29 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [  7 124]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9538461538461538\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8245614035087719\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 30 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [  4 127]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9548872180451129\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 31 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [  8 123]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9425287356321839\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8421052631578947\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 32 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [  3 128]]\n",
      "Train Acc : 0.9758064516129032\n",
      "Train F1-Score : 0.9660377358490565\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 33 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.831858407079646\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 34 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 35 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.831858407079646\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# n_estimators\n",
    "n_tree = [5, 10, 20]\n",
    "# learning_rate\n",
    "l_rate = [0.1, 0.3]\n",
    "# max_depth\n",
    "m_depth = [3, 5]\n",
    "# reg_alpha\n",
    "L1_norm = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Modeling\n",
    "save_n = []\n",
    "save_l = []\n",
    "save_m = []\n",
    "save_L1 = []\n",
    "f1_score_ = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for n in n_tree:\n",
    "    for l in l_rate:\n",
    "        for m in m_depth:\n",
    "            for L1 in L1_norm:\n",
    "                \n",
    "                print(\">>> {} <<<\".format(cnt))\n",
    "                cnt +=1\n",
    "                print(\"n_estimators : {}, learning_rate : {}, max_depth : {}, reg_alpha : {}\".format(n, l, m, L1))\n",
    "                model = XGBClassifier(n_estimators=n, learning_rate=l, \n",
    "                                      max_depth=m, reg_alpha=L1, objective='binary:logistic', random_state=119)\n",
    "                model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "                \n",
    "                \n",
    "                # Train Acc\n",
    "                y_pre_train = model.predict(X.iloc[train_idx])\n",
    "                cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "                print(\"Train Confusion Matrix\")\n",
    "                print(cm_train)\n",
    "                print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "                print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "                # Test Acc\n",
    "                y_pre_test = model.predict(X.iloc[valid_idx])\n",
    "                cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "                print(\"Test Confusion Matrix\")\n",
    "                print(cm_test)\n",
    "                print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "                print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                save_n.append(n)\n",
    "                save_l.append(l)\n",
    "                save_m.append(m)\n",
    "                save_L1.append(L1)\n",
    "                f1_score_.append(f1_score(Y.iloc[valid_idx], y_pre_test))\n",
    "                \n",
    "                # Model 저장\n",
    "                #import joblib\n",
    "                #joblib.dump(model, './XGBoost_model/Result_{}_{}_{}_{}_{}.pkl'.format(n, l, m, L1, round(f1_score_[-1], 4)))\n",
    "                #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "Best Test f1-score : 0.8648648648648649\n",
      "Best n_estimators : 5\n",
      "Best Learning Rate : 0.1\n",
      "Best Max_depth : 3\n",
      "Best L1-norm : 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\">>> {} <<<\\nBest Test f1-score : {}\\nBest n_estimators : {}\\nBest Learning Rate : {}\\nBest Max_depth : {}\\nBest L1-norm : {}\".format(np.argmax(f1_score_),\n",
    "                                                                                                                                            f1_score_[np.argmax(f1_score_)], \n",
    "                                                                                                                                            save_n[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_l[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_m[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_L1[np.argmax(f1_score_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[230  11]\n",
      " [ 29 102]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8360655737704918\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators=save_n[np.argmax(f1_score_)], learning_rate=save_l[np.argmax(f1_score_)], \n",
    "                           max_depth=save_m[np.argmax(f1_score_)], reg_alpha=save_L1[np.argmax(f1_score_)], objective='binary:logistic', \n",
    "                           random_state=119)\n",
    "best_model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "\n",
    "# Train Acc\n",
    "y_pre_train = best_model.predict(X.iloc[train_idx])\n",
    "cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(cm_train)\n",
    "print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "# Test Acc\n",
    "y_pre_test = best_model.predict(X.iloc[valid_idx])\n",
    "cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(cm_test)\n",
    "print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
